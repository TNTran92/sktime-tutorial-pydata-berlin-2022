{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sktime - A Unified Framework for Machine Learning with Time Series\n",
    "\n",
    "Tutorial at the PyData Global 2021\n",
    "\n",
    "Find out more at: https://github.com/alan-turing-institute/sktime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hierarchical time series\n",
    "\n",
    "In typical business use cases, time series often present in hierarchical from.\n",
    "\n",
    "### Data\n",
    "\n",
    "<img src=\"./img/hierarchytree.png\" width=\"1200\" alt=\"arrow heads\">\n",
    "\n",
    "Examples include:\n",
    "* Product sales in different categories (e.g. M5 time series competition)\n",
    "* Tourism demand in different regions\n",
    "* Balance sheet structures across cost centers / accounts\n",
    "\n",
    "Many hierarchical time series datasets can be found here:\n",
    "https://forecastingdata.org/\n",
    "(SKTIME is working on a loader to easily access data in this repo)\n",
    "\n",
    "\n",
    "For literature see also:\n",
    "https://otexts.com/fpp2/hierarchical.html\n",
    "\n",
    "The above example shows a clean hierarchy tree leading from the top level strictly\n",
    "downwards to lower level branches. In practice, we can also often see a more complicated \n",
    "aggregation structure where the product hierarchy and the geographic hierarchy can \n",
    "both be used together. \n",
    "\n",
    "<img src=\"./img/hierarchytree_grouped.png\" width=\"1200\" alt=\"arrow heads\">\n",
    "\n",
    "\n",
    "# How does sktime represent hierarchical data?\n",
    "# General intro to sktime datatypes\n",
    "\n",
    "`sktime` provides modules for a number of time series related learning tasks.\n",
    "\n",
    "These modules use `sktime` specific in-memory (i.e., python workspace) representations for time series and related objects, most importantly individual time series and time series panels. `sktime`'s in-memory representations rely on `pandas` and `numpy`, with additional conventions on the `pandas` and `numpy` object.\n",
    "\n",
    "Users of `sktime` should be aware of these representations, since presenting the data in an `sktime` compatible representation is usually the first step in using any of the `sktime` modules.\n",
    "\n",
    "This notebook introduces the data types used in `sktime`, related functionality such as converters and validity checkers, and common workflows for loading and conversion:\n",
    "\n",
    "**Section 1** introduces in-memory data containers used in `sktime`, with examples.\n",
    "\n",
    "**Section 2** introduces validity checkers and conversion functionality for in-memory data containers.\n",
    "\n",
    "**Section 3** introduces common workflows to load data from file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to retrieve examples\n",
    "from sktime.datatypes import get_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1.1: Time series - the `\"pd.DataFrame\"` mtype\n",
    "\n",
    "In the `\"pd.DataFrame\"` mtype, time series are represented by an in-memory container `obj: pandas.DataFrame` as follows.\n",
    "\n",
    "* structure convention: `obj.index` must be monotonous, and one of `Int64Index`, `RangeIndex`, `DatetimeIndex`, `PeriodIndex`.\n",
    "* variables: columns of `obj` correspond to different variables\n",
    "* variable names: column names `obj.columns`\n",
    "* time points: rows of `obj` correspond to different, distinct time points\n",
    "* time index: `obj.index` is interpreted as a time index.\n",
    "* capabilities: can represent multivariate series; can represent unequally spaced series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(mtype=\"pd.DataFrame\", as_scitype=\"Series\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a bivariate series in `\"pd.DataFrame\"` representation.\n",
    "This series has two variables, named `\"a\"` and `\"b\"`. Both are observed at the same four time points 0, 1, 2, 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "1. Model specification\n",
    "2. Fitting\n",
    "3. Prediction\n",
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a         b\n",
       "0  1.0  3.000000\n",
       "1  4.0  7.000000\n",
       "2  0.5  2.000000\n",
       "3 -3.0 -0.428571"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_examples(mtype=\"pd.DataFrame\", as_scitype=\"Series\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2: Time series panels - the `\"Panel\"` scitype\n",
    "\n",
    "The major representations of time series panels in `sktime` are:\n",
    "\n",
    "* `\"pd-multiindex\"` - a `pandas.DataFrame`, with row multi-index (`instances`, `timepoints`), cols = variables\n",
    "* `\"numpy3D\"` - a 3D `np.ndarray`, with axis 0 = instances, axis 1 = variables, axis 2 = time points\n",
    "* `\"df-list\"` - a `list` of `pandas.DataFrame`, with list index = instances, data frame rows = time points, data frame cols = variables\n",
    "\n",
    "These representations are considered primary representations in `sktime` and are core to internal computations.\n",
    "\n",
    "There are further, minor representations of time series panels in `sktime`:\n",
    "\n",
    "* `\"nested_univ\"` - a `pandas.DataFrame`, with `pandas.Series` in cells. data frame rows = instances, data frame cols = variables, and series axis = time points\n",
    "* `\"numpyflat\"` - a 2D `np.ndarray` with rows = instances, and columns indexed by a pair index of (variables, time points). This format is only being converted to and cannot be converted from (since number of variables and time points may be ambiguous).\n",
    "* `\"pd-wide\"` - a `pandas.DataFrame` in wide format: has column multi-index (variables, time points), rows = instances; the \"variables\" index can be omitted for univariate time series\n",
    "* `\"pd-long\"` - a `pandas.DataFrame` in long format: has cols `instances`, `timepoints`, `variable`, `value`; entries in `value` are indexed by tuples of values in (`instances`, `timepoints`, `variable`).\n",
    "\n",
    "The minor representations are currently not fully consolidated in-code and are not discussed further below. Contributions are appreciated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2.1: Time series panels - the `\"pd-multiindex\"` mtype\n",
    "\n",
    "In the `\"pd-multiindex\"` mtype, time series panels are represented by an in-memory container `obj: pandas.DataFrame` as follows.\n",
    "\n",
    "* structure convention: `obj.index` must be a pair multi-index of type `(RangeIndex, t)`, where `t` is one of `Int64Index`, `RangeIndex`, `DatetimeIndex`, `PeriodIndex` and monotonous. `obj.index` must have name `(\"instances\", \"timepoints\")`.\n",
    "* instances: rows with the same `\"instances\"` index correspond to the same instance; rows with different `\"instances\"` index correspond to different instances.\n",
    "* instance index: the first element of pairs in `obj.index` is interpreted as an instance index. \n",
    "* variables: columns of `obj` correspond to different variables\n",
    "* variable names: column names `obj.columns`\n",
    "* time points: rows of `obj` with the same `\"timepoints\"` index correspond correspond to the same time point; rows of `obj` with different `\"timepoints\"` index correspond correspond to the different time points.\n",
    "* time index: the second element of pairs in `obj.index` is interpreted as a time index. \n",
    "* capabilities: can represent panels of multivariate series; can represent unequally spaced series; can represent panels of unequally supported series; cannot represent panels of series with different sets of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a panel of multivariate series in `\"pd-multiindex\"` mtype representation.\n",
    "The panel contains three multivariate series, with instance indices 0, 1, 2. All series have two variables with names `\"var_0\"`, `\"var_1\"`. All series are observed at three time points 0, 1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_examples(mtype=\"pd-multiindex\", as_scitype=\"Panel\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2.2: Hierarchical types\n",
    "* structure convention: `obj.index` must be a  multi-index of type `(RangeIndex, t)`, where `t` is one of `Int64Index`, `RangeIndex`, `DatetimeIndex`, `PeriodIndex` and monotonous. `obj.index` must multi column names, which the last column being `(\"\"timepoints\")`.\n",
    "* instances: rows with the same `\"instances\"` index correspond to the same instance; rows with different `\"instances\"` index correspond to different instances.\n",
    "* instance index: the first element of pairs in `obj.index` is interpreted as an instance index. \n",
    "* variables: columns of `obj` correspond to different variables\n",
    "* variable names: column names `obj.columns`\n",
    "* time points: rows of `obj` with the same `\"timepoints\"` index correspond correspond to the same time point; rows of `obj` with different `\"timepoints\"` index correspond correspond to the different time points.\n",
    "* time index: the second element of pairs in `obj.index` is interpreted as a time index. \n",
    "* capabilities: can represent panels of multivariate series; can represent unequally spaced series; can represent panels of unequally supported series; cannot represent panels of series with different sets of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances_0</th>\n",
       "      <th>instances_1</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">a</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">b</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    var_0  var_1\n",
       "instances_0 instances_1 timepoints              \n",
       "a           0           0               1      4\n",
       "                        1               2      5\n",
       "                        2               3      6\n",
       "            1           0               1      4\n",
       "                        1               2     55\n",
       "                        2               3      6\n",
       "            2           0               1     42\n",
       "                        1               2      5\n",
       "                        2               3      6\n",
       "b           0           0               1      4\n",
       "                        1               2      5\n",
       "                        2               3      6\n",
       "            1           0               1      4\n",
       "                        1               2     55\n",
       "                        2               3      6\n",
       "            2           0               1     42\n",
       "                        1               2      5\n",
       "                        2               3      6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Example generation for testing.\n",
    "Example of two-dimensional hierarchy\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "###\n",
    "# example 0: multivariate, equally sampled\n",
    "\n",
    "cols = [\"instances_0\", \"instances_1\", \"timepoints\"] + [f\"var_{i}\" for i in range(2)]\n",
    "\n",
    "Xlist = [\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", 0, 0, 1, 4], [\"a\", 0, 1, 2, 5], [\"a\", 0, 2, 3, 6]], columns=cols\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", 1, 0, 1, 4], [\"a\", 1, 1, 2, 55], [\"a\", 1, 2, 3, 6]], columns=cols\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", 2, 0, 1, 42], [\"a\", 2, 1, 2, 5], [\"a\", 2, 2, 3, 6]], columns=cols\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", 0, 0, 1, 4], [\"b\", 0, 1, 2, 5], [\"b\", 0, 2, 3, 6]], columns=cols\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", 1, 0, 1, 4], [\"b\", 1, 1, 2, 55], [\"b\", 1, 2, 3, 6]], columns=cols\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", 2, 0, 1, 42], [\"b\", 2, 1, 2, 5], [\"b\", 2, 2, 3, 6]], columns=cols\n",
    "    ),\n",
    "]\n",
    "\n",
    "X = pd.concat(Xlist)\n",
    "X = X.set_index([\"instances_0\", \"instances_1\", \"timepoints\"])\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index.get_level_values(level=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical forecasting\n",
    "* data with hierarchical format can be forecast based on one of the different panel\n",
    "mtypes\n",
    "* forecasts that are generated this way are independent of each other\n",
    "* if we add up these forecasts, we get consistent forecasts that sum up across\n",
    "dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py:64: UserWarning: No module named 'pmdarima'. 'pmdarima' is a soft dependency and not included in the sktime installation. Please run: `pip install pmdarima` to install the pmdarima package. To install all soft dependencies, run: `pip install sktime[all_extras]`\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ARIMA requires package 'pmdarima' in python environment to be instantiated, but 'pmdarima' was not found. 'pmdarima' is a soft dependency and not included in the base sktime installation. Please run: `pip install pmdarima` to install the pmdarima package. To install all soft dependencies, run: `pip install sktime[all_extras]`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py:40\u001b[0m, in \u001b[0;36m_check_soft_dependencies\u001b[0;34m(severity, object, suppress_import_stdout, *packages)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=38'>39</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=39'>40</a>\u001b[0m         import_module(package)\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=40'>41</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/importlib/__init__.py?line=125'>126</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/importlib/__init__.py?line=126'>127</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:973\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pmdarima'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/ds40/pydata_berlin/sktime-tutorial-pydata-berlin-2022/notebooks/hierarchy_global.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/ds40/pydata_berlin/sktime-tutorial-pydata-berlin-2022/notebooks/hierarchy_global.ipynb#ch0000017vscode-remote?line=8'>9</a>\u001b[0m y \u001b[39m=\u001b[39m _make_panel_X(n_instances\u001b[39m=\u001b[39mn_instances, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/ds40/pydata_berlin/sktime-tutorial-pydata-berlin-2022/notebooks/hierarchy_global.ipynb#ch0000017vscode-remote?line=9'>10</a>\u001b[0m y \u001b[39m=\u001b[39m convert(y, from_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnested_univ\u001b[39m\u001b[39m\"\u001b[39m, to_type\u001b[39m=\u001b[39mPANEL_MTYPES[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/ds40/pydata_berlin/sktime-tutorial-pydata-berlin-2022/notebooks/hierarchy_global.ipynb#ch0000017vscode-remote?line=11'>12</a>\u001b[0m y_pred \u001b[39m=\u001b[39m ARIMA()\u001b[39m.\u001b[39mfit(y)\u001b[39m.\u001b[39mpredict([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/ds40/pydata_berlin/sktime-tutorial-pydata-berlin-2022/notebooks/hierarchy_global.ipynb#ch0000017vscode-remote?line=12'>13</a>\u001b[0m valid, _, metadata \u001b[39m=\u001b[39m check_is_mtype(y_pred, PANEL_MTYPES[\u001b[39m0\u001b[39m], return_metadata\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/pydata_berlin/sktime/sktime/forecasting/arima.py:588\u001b[0m, in \u001b[0;36mARIMA.__init__\u001b[0;34m(self, order, seasonal_order, start_params, method, maxiter, suppress_warnings, out_of_sample_size, scoring, scoring_args, trend, with_intercept, **sarimax_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=571'>572</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=572'>573</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=573'>574</a>\u001b[0m     order\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=584'>585</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msarimax_kwargs\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=585'>586</a>\u001b[0m ):\n\u001b[0;32m--> <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=587'>588</a>\u001b[0m     _check_soft_dependencies(\u001b[39m\"\u001b[39;49m\u001b[39mpmdarima\u001b[39;49m\u001b[39m\"\u001b[39;49m, severity\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mobject\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=589'>590</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder \u001b[39m=\u001b[39m order\n\u001b[1;32m    <a href='file:///home/ds40/pydata_berlin/sktime/sktime/forecasting/arima.py?line=590'>591</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseasonal_order \u001b[39m=\u001b[39m seasonal_order\n",
      "File \u001b[0;32m~/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py:62\u001b[0m, in \u001b[0;36m_check_soft_dependencies\u001b[0;34m(severity, object, suppress_import_stdout, *packages)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=51'>52</a>\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=52'>53</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mclass_name\u001b[39m}\u001b[39;00m\u001b[39m requires package \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpackage\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m in python \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=53'>54</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menvironment to be instantiated, but \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpackage\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was not found. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=58'>59</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msktime[all_extras]`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=59'>60</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=60'>61</a>\u001b[0m \u001b[39mif\u001b[39;00m severity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=61'>62</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=62'>63</a>\u001b[0m \u001b[39melif\u001b[39;00m severity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwarning\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='file:///home/ds40/pydata_berlin/sktime/sktime/utils/validation/_dependencies.py?line=63'>64</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: ARIMA requires package 'pmdarima' in python environment to be instantiated, but 'pmdarima' was not found. 'pmdarima' is a soft dependency and not included in the base sktime installation. Please run: `pip install pmdarima` to install the pmdarima package. To install all soft dependencies, run: `pip install sktime[all_extras]`"
     ]
    }
   ],
   "source": [
    "from sktime.datatypes import check_is_mtype, convert\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "from sktime.utils._testing.panel import _make_panel_X\n",
    "n_instances = 10\n",
    "PANEL_MTYPES = [\"pd-multiindex\", \"nested_univ\", \"numpy3D\"]\n",
    "HIER_MTYPES = [\"pd_multiindex_hier\"]\n",
    "\n",
    "y = _make_panel_X(n_instances=n_instances, random_state=42)\n",
    "y = convert(y, from_type=\"nested_univ\", to_type=PANEL_MTYPES[0])\n",
    "\n",
    "y_pred = ARIMA().fit(y).predict([1, 2, 3])\n",
    "valid, _, metadata = check_is_mtype(y_pred, PANEL_MTYPES[0], return_metadata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical forecasting - challenges\n",
    "* The above approach is called \"bottom up reconciliation\"\n",
    "* There exist other reconciliation approaches \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global forecasting vs Univariate Forecasting\n",
    "\n",
    "\n",
    "\n",
    "\"Many businesses nowadays rely on large quantities of time series data making time \n",
    "series forecasting an important research area. Global forecasting models [that] are trained\n",
    " **across sets of time series** have shown huge potential in providing accurate forecasts compared\n",
    " with the univariate forecasting models that work on isolated series.\"\n",
    "\n",
    "<img src=\"./img/flow.png\" width=\"400\" alt=\"arrow heads\">\n",
    "\n",
    "https://robjhyndman.com/publications/monash-forecasting-data/\n",
    "\n",
    " Why does global forecasting matter?\n",
    " * In practice, we often have time series of limited range\n",
    " * Estimation is difficult, and we cannot model complex dependencies\n",
    " * Assumption of global forecasting: We can observe the identical data generating process (DGP) multiple times\n",
    " * Non-identical DGPs can be fine too, as long as the degree of dissimilarity is captured by exogeneous information\n",
    " * Now we have much more information and can estimate more reliably and more complex models (caveat: unless complexity is purely driven by time dynamics)\n",
    " \n",
    "As a result of these advantages, global forecasting models have been very successful in competition, e.g.\n",
    "* Rossmann Store Sales\n",
    "* Walmart Sales in Stormy Weather\n",
    "* M5 competition\n",
    "\n",
    "Many business problems in practice are essentially global forecasting problem - often also reflecting hierarchical information (see above)\n",
    "* Product sales in different categories (e.g. M5 time series competition)\n",
    "* Balance sheet structures across cost centers / accounts\n",
    "* Dynamics of pandemics observed at different points in time\n",
    "\n",
    "Distinction to multivariate forecasting\n",
    "* Multivariate forecasting focuses on modeling interdependence between time series\n",
    "* Global can model interdependence, but focus lies on enhancing observation space\n",
    "\n",
    "Implementation in sktime\n",
    "* Multivariate forecasting models are supported in sktime via ? VAR...* \n",
    "* Global forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following example we will use the `\"pd-multiindex\"` representation of the `\"Panel\"` scitype discussed in Section 1.2. \n",
    "\n",
    "In that case, `\"instances\"` is the unique identifier for the individual time series, while `\"timepoints\"` captures the time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sktime.forecasting.compose import ForecastingPipeline, make_reduction\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "from sktime.transformations.series.date import DateTimeFeatures\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# %%\n",
    "# Load M5 Data and prepare\n",
    "y = pd.read_pickle(\"global_fc/y.pkl\")\n",
    "X = pd.read_pickle(\"global_fc/X.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is based on the M5 competition. The data features sales of products in \n",
    "different stores, different states and different product categories. \n",
    "\n",
    "For a detailed analysis of the competition please take a look at the paper \n",
    "\"M5 accuracy competition: Results, findings, and conclusions\".\n",
    "\n",
    "\n",
    "https://doi.org/10.1016/j.ijforecast.2021.11.013\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see \n",
    "a glimpse of the data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            y\n",
      "instances timepoints         \n",
      "1         2016-03-15   756.67\n",
      "          2016-03-16   679.13\n",
      "          2016-03-17   633.40\n",
      "          2016-03-18  1158.04\n",
      "          2016-03-19   914.24\n",
      "                      dept_id  cat_id  store_id  state_id  event_name_1  \\\n",
      "instances timepoints                                                      \n",
      "1         2016-03-15        1       1        10         3             1   \n",
      "          2016-03-16        1       1        10         3             1   \n",
      "          2016-03-17        1       1        10         3             7   \n",
      "          2016-03-18        1       1        10         3             1   \n",
      "          2016-03-19        1       1        10         3             1   \n",
      "\n",
      "                      event_type_1  event_name_2  event_type_2  snap  \\\n",
      "instances timepoints                                                   \n",
      "1         2016-03-15             1             1             1     3   \n",
      "          2016-03-16             1             1             1     0   \n",
      "          2016-03-17             3             1             1     0   \n",
      "          2016-03-18             1             1             1     0   \n",
      "          2016-03-19             1             1             1     0   \n",
      "\n",
      "                      no_stock_days  \n",
      "instances timepoints                 \n",
      "1         2016-03-15              0  \n",
      "          2016-03-16              0  \n",
      "          2016-03-17              0  \n",
      "          2016-03-18              0  \n",
      "          2016-03-19              0  \n"
     ]
    }
   ],
   "source": [
    "print(y.head())\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data set consists out of time series grouped via the instances argument in the first column\n",
    "of the multiindex. We will focus on modeling individual products. The hierarchical \n",
    "information is provided as exgoneous information. \n",
    "\n",
    "For the M5 competition, winning solution used exogeneous features about the hierarchies like `\"dept_id\"`, `\"store_id\"` etc. to capture similarities and dissimilarities of the products. Other features include holiday events and snap days (specific assisstance program of US social security paid on certain days)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split into test and train set using temporal_train_test_split. SKTIME supports \n",
    "splitting instances for time series data, i.e. to cut every instance of the time series individually. Splitting is as simple as this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>756.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>679.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>633.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>1158.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>914.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y\n",
       "instances timepoints         \n",
       "1         2016-03-15   756.67\n",
       "          2016-03-16   679.13\n",
       "          2016-03-17   633.40\n",
       "          2016-03-18  1158.04\n",
       "          2016-03-19   914.24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>2016-04-14</th>\n",
       "      <td>874.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-15</th>\n",
       "      <td>895.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-16</th>\n",
       "      <td>1112.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-17</th>\n",
       "      <td>1014.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-18</th>\n",
       "      <td>691.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y\n",
       "instances timepoints         \n",
       "1         2016-04-14   874.57\n",
       "          2016-04-15   895.29\n",
       "          2016-04-16  1112.63\n",
       "          2016-04-17  1014.86\n",
       "          2016-04-18   691.91"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X)\n",
    "display(y_train.head(5))\n",
    "display(y_test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKTIME will make sure that both y and X are split in the same way, and also preserve the structure of the hierarchies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationale for tree based models\n",
    "\n",
    "Tree based models possess some unique advantages and disadvantages when applied to the domain of time series.\n",
    "They are able to exploit complex non-linear relationships / dependencies between time series and covariates, but also possess plenty of hyperparameters and -at least out of the box- cannot extrapolate.\n",
    "\n",
    "In **univariate time series forecasting**, tree based models often do not have enough data to reliably train hyperparameters, and statistical models like ARIMA or ETS are often superior. \n",
    "\n",
    "But due to the abundance of data in **global forecasting** - the M5 competition contained 42,840 time series -  the advantages of those models can begin to shine.\n",
    "\n",
    "SKTIME supports all major Python implementations of tree based models. In this example we will use a Random Forest Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = make_pipeline(\n",
    "    RandomForestRegressor(random_state=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One big caveat with tree based models is the fact they are not time series models per se and therefore do not understand concepts like autocorrelation or seasonalities. \n",
    "\n",
    "As a result, we need to generate appropriate features that capture the dynamics of the time series. In sktime we have the transformer  `\"WindowSummarizer\"` to capture that time dependence.\n",
    "\n",
    "The `\"WindowSummarizer\"` can be used to generate features useful for time series forecasting based on a provided dictionary of functions, window shifts and window lengths.\n",
    "\n",
    "See the following example for an application of `\"WindowSummarizer\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "#y = load_airline()\n",
    "kwargs = {\n",
    "        \"lag_feature\": {\n",
    "            \"lag\": [1],\n",
    "            \"mean\": [[1, 3], [3, 6]],\n",
    "            \"std\": [[1, 4]],\n",
    "        }\n",
    "    }\n",
    "\n",
    "transformer = WindowSummarizer(**kwargs)\n",
    "y_transformed = transformer.fit_transform(y_train)\n",
    "\n",
    "display(y_transformed.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation `\"mean\": [[1, 3]]` (captured in the column `\"y_mean_1_3\"`) can be interpreted in the following way:\n",
    "\n",
    "The summarization function `\"mean\": [[1, 3]]` is applied to the a window of length 3 lagged by one period when compare to the observation we want to forecast. This can be visualized in the following way (from the docs):\n",
    "\n",
    "    For `window = [1, 3]`, we have a `lag` of 1 and `window_length` of 3 to target the three last days (exclusive z) that were observed. Summarization is done across windows like this:\n",
    "    |-------------------------- |\n",
    "    | x x x x x x x x * * * z x |\n",
    "    |---------------------------|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `\"WindowSummarizer\"` uses pandas rolling window functions to allow for a speedy generation of features. \n",
    "* \"sum\",\n",
    "* \"mean\",\n",
    "* \"median\",\n",
    "* \"std\",\n",
    "* \"var\",\n",
    "* \"kurt\",\n",
    "* \"min\",\n",
    "* \"max\",\n",
    "* \"corr\",\n",
    "* \"cov\",\n",
    "* \"skew\",\n",
    "* \"sem\"\n",
    "\n",
    "These functions are typically very fast since they are optimized for rolling, grouped operations. \n",
    "\n",
    "In the M5 competition, arguably the most relevant features were:\n",
    "\n",
    "* **mean** calculations to capture level shifts, e.g. last week sales, sales of the week prior to the last month etc.\n",
    "* **standard deviation** to capture increases / decreases in volatility in sales, and how it impacts future sales\n",
    "* rolling **skewness** / **kurtosis** calculations, to capture changes in store sales tendencies.\n",
    "* various different calculations to capture periods of zero sales (e.g. out of stock scenarios)\n",
    "\n",
    "Only the first three calculations can be implemented using native pandas functions. You can, however, also provide any other arbitrary function to WindowSummarizer, either programmed by you, or from an external package. \n",
    "\n",
    "In this example, we will define the function `count_gt130` to count how many observations lie above the threshold of 130 within a window of length 3, lagged by 2 periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def count_gt130(x):\n",
    "    \"\"\"Count how many observations lie above threshold 130.\"\"\"\n",
    "    return np.sum((x > 700)[::-1])\n",
    "\n",
    "y = load_airline()\n",
    "kwargs = {\n",
    "        \"lag_feature\": {\n",
    "            \"lag\": [1],\n",
    "            count_gt130: [[2, 3]],\n",
    "            \"std\": [[1, 4]],\n",
    "        }\n",
    "    }\n",
    "\n",
    "transformer = WindowSummarizer(**kwargs)\n",
    "y_transformed = transformer.fit_transform(y_train)\n",
    "\n",
    "display(y_transformed.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other arguments you can provide to `\"WindowSummarizer\"` are:\n",
    "\n",
    "    n_jobs : int, optional (default=-1)\n",
    "        The number of jobs to run in parallel for applying the window functions.\n",
    "        ``-1`` means using all processors.\n",
    "    target_cols: list of str, optional (default = None)\n",
    "        Specifies which columns in X to target for applying the window functions.\n",
    "        ``None`` will target the first column\n",
    "\n",
    "In a global forecasting setting, you typically want to target primarly `y`. However, sometimes you also want to apply `\"WindowSummarizer\"` to some columns in `X`. Use \n",
    "`\"target_cols\"` to specify which columns and apply `\"WindowSummarizer\"` within a `\"ForecastingPipeline\"`.\n",
    "\n",
    "In the M5 competition, lagging of exogeneous features was especially useful for lags around holiday dummies (often sales are affected for a few days before and after major holidays) as well as changes in item prices (discounts as well as persistent price changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1959    67075.727273\n",
       "1960    67638.454545\n",
       "1961    68201.181818\n",
       "1962    68763.909091\n",
       "Freq: A-DEC, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.datasets import load_longley\n",
    "y_ll, X_ll = load_longley()\n",
    "y_train_ll, y_test_ll, X_train_ll, X_test_ll = temporal_train_test_split(y_ll, X_ll)\n",
    "fh = ForecastingHorizon(X_test_ll.index, is_relative=False)\n",
    "# Example transforming only X\n",
    "pipe = ForecastingPipeline(\n",
    "    steps=[\n",
    "        (\"a\", WindowSummarizer(n_jobs=1, target_cols=[\"POP\", \"GNPDEFL\"])),\n",
    "        (\"b\", WindowSummarizer(n_jobs=1, target_cols=[\"GNP\"], **kwargs)),\n",
    "        (\"forecaster\", NaiveForecaster(strategy=\"drift\")),\n",
    "    ]\n",
    ")\n",
    "pipe_return = pipe.fit(y_train_ll, X_train_ll)\n",
    "y_pred1 = pipe_return.predict(fh=fh, X=X_test_ll)\n",
    "display(y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global forecasting models are often very performance and resource intensive. To address that, we have implemented an en-bloc approach in sktime to directly compute \n",
    "the relevant features in a parallel way. You can use that functionality by passing the WindowSummarizer as a transformer within our make_reduction function. \n",
    "\n",
    "In this case, you do not need to set a window_length, since it will be inferred from the WindowSummarizer (taking a look at the features that goes furthest back into time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = make_reduction(\n",
    "    regressor,\n",
    "    scitype=\"tabular-regressor\",\n",
    "    transformers=[WindowSummarizer(**kwargs, n_jobs=1)],\n",
    "    window_length=None,\n",
    "    strategy=\"recursive\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, concepts relating to calendar seasonalities are also not understood by tree based models and need to be provided by means of feature engineering. This relates for example to:\n",
    "* day of the week effects historically observed for stock prices (prices on Fridays used to differ from Monday prices).\n",
    "* used car prices being higher in spring than in summer\n",
    "* spendings at the beginning of the month differing from end of month due to salary effects.\n",
    "\n",
    "\n",
    "Calendar seasonalities can be modeled by means of dummy variables or fourier terms. As a rule of thumb, use dummy variables for discontinous effects and fourier terms when you believe there is a certain degree of smoothness in the seasonality.\n",
    "\n",
    "SKTIME currently supports the generation of calendar dummy variables via the DateTimeFeatures transformer. You can either manually specify the desired seasonality or provide to DateTimeFeatures the base frequency of the time series (daily, weekly etc.) and the desired complexity (few vs many features) and DateTimeFeatures will pick a set of sensible seasonalities. SKTIME will support fourier terms in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-20</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-21</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-22</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-23</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-24</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-25</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">2</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-20</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-21</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-22</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-23</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-24</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-25</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      year  month  weekday\n",
       "instances timepoints                      \n",
       "1         2016-03-15  2016      3        1\n",
       "          2016-03-16  2016      3        2\n",
       "          2016-03-17  2016      3        3\n",
       "          2016-03-18  2016      3        4\n",
       "          2016-03-19  2016      3        5\n",
       "          2016-03-20  2016      3        6\n",
       "          2016-03-21  2016      3        0\n",
       "          2016-03-22  2016      3        1\n",
       "          2016-03-23  2016      3        2\n",
       "          2016-03-24  2016      3        3\n",
       "          2016-03-25  2016      3        4\n",
       "          2016-03-26  2016      3        5\n",
       "          2016-03-27  2016      3        6\n",
       "          2016-03-28  2016      3        0\n",
       "          2016-03-29  2016      3        1\n",
       "          2016-03-30  2016      3        2\n",
       "          2016-03-31  2016      3        3\n",
       "          2016-04-01  2016      4        4\n",
       "          2016-04-02  2016      4        5\n",
       "          2016-04-03  2016      4        6\n",
       "          2016-04-04  2016      4        0\n",
       "          2016-04-05  2016      4        1\n",
       "          2016-04-06  2016      4        2\n",
       "          2016-04-07  2016      4        3\n",
       "          2016-04-08  2016      4        4\n",
       "          2016-04-09  2016      4        5\n",
       "          2016-04-10  2016      4        6\n",
       "          2016-04-11  2016      4        0\n",
       "          2016-04-12  2016      4        1\n",
       "          2016-04-13  2016      4        2\n",
       "2         2016-03-15  2016      3        1\n",
       "          2016-03-16  2016      3        2\n",
       "          2016-03-17  2016      3        3\n",
       "          2016-03-18  2016      3        4\n",
       "          2016-03-19  2016      3        5\n",
       "          2016-03-20  2016      3        6\n",
       "          2016-03-21  2016      3        0\n",
       "          2016-03-22  2016      3        1\n",
       "          2016-03-23  2016      3        2\n",
       "          2016-03-24  2016      3        3\n",
       "          2016-03-25  2016      3        4\n",
       "          2016-03-26  2016      3        5\n",
       "          2016-03-27  2016      3        6\n",
       "          2016-03-28  2016      3        0\n",
       "          2016-03-29  2016      3        1\n",
       "          2016-03-30  2016      3        2\n",
       "          2016-03-31  2016      3        3\n",
       "          2016-04-01  2016      4        4\n",
       "          2016-04-02  2016      4        5\n",
       "          2016-04-03  2016      4        6\n",
       "          2016-04-04  2016      4        0\n",
       "          2016-04-05  2016      4        1\n",
       "          2016-04-06  2016      4        2\n",
       "          2016-04-07  2016      4        3\n",
       "          2016-04-08  2016      4        4\n",
       "          2016-04-09  2016      4        5\n",
       "          2016-04-10  2016      4        6\n",
       "          2016-04-11  2016      4        0\n",
       "          2016-04-12  2016      4        1\n",
       "          2016-04-13  2016      4        2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = DateTimeFeatures(ts_freq=\"D\")\n",
    "X_hat = transformer.fit_transform(X_train)\n",
    "\n",
    "new_cols = [i for i in X_hat if not i in X_train.columns]\n",
    "display(X_hat[new_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DateTimeFeatures supports the following frequencies:\n",
    "* Y - year\n",
    "* Q - quarter\n",
    "* M - month\n",
    "* W - week\n",
    "* D - day\n",
    "* H - hour\n",
    "* T - minute\n",
    "* S - second\n",
    "* L - millisecond\n",
    "\n",
    "You can specify the manual generation of dummy features with the notation e.g. \"day_of_month\", \"day_of_week\", \"week_of_quarter\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>day_of_quarter</th>\n",
       "      <th>week_of_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-20</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-21</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-22</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-23</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-24</th>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-25</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">2</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-16</th>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-17</th>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-18</th>\n",
       "      <td>78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-19</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-20</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-21</th>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-22</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-23</th>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-24</th>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-25</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-26</th>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-27</th>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-28</th>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-29</th>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-30</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-02</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-03</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-04</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-05</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-06</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-07</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-08</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-09</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-11</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-12</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-13</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      day_of_quarter  week_of_month\n",
       "instances timepoints                               \n",
       "1         2016-03-15              75              3\n",
       "          2016-03-16              76              3\n",
       "          2016-03-17              77              3\n",
       "          2016-03-18              78              3\n",
       "          2016-03-19              79              3\n",
       "          2016-03-20              80              3\n",
       "          2016-03-21              81              3\n",
       "          2016-03-22              82              4\n",
       "          2016-03-23              83              4\n",
       "          2016-03-24              84              4\n",
       "          2016-03-25              85              4\n",
       "          2016-03-26              86              4\n",
       "          2016-03-27              87              4\n",
       "          2016-03-28              88              4\n",
       "          2016-03-29              89              5\n",
       "          2016-03-30              90              5\n",
       "          2016-03-31              91              5\n",
       "          2016-04-01               1              1\n",
       "          2016-04-02               2              1\n",
       "          2016-04-03               3              1\n",
       "          2016-04-04               4              1\n",
       "          2016-04-05               5              1\n",
       "          2016-04-06               6              1\n",
       "          2016-04-07               7              1\n",
       "          2016-04-08               8              2\n",
       "          2016-04-09               9              2\n",
       "          2016-04-10              10              2\n",
       "          2016-04-11              11              2\n",
       "          2016-04-12              12              2\n",
       "          2016-04-13              13              2\n",
       "2         2016-03-15              75              3\n",
       "          2016-03-16              76              3\n",
       "          2016-03-17              77              3\n",
       "          2016-03-18              78              3\n",
       "          2016-03-19              79              3\n",
       "          2016-03-20              80              3\n",
       "          2016-03-21              81              3\n",
       "          2016-03-22              82              4\n",
       "          2016-03-23              83              4\n",
       "          2016-03-24              84              4\n",
       "          2016-03-25              85              4\n",
       "          2016-03-26              86              4\n",
       "          2016-03-27              87              4\n",
       "          2016-03-28              88              4\n",
       "          2016-03-29              89              5\n",
       "          2016-03-30              90              5\n",
       "          2016-03-31              91              5\n",
       "          2016-04-01               1              1\n",
       "          2016-04-02               2              1\n",
       "          2016-04-03               3              1\n",
       "          2016-04-04               4              1\n",
       "          2016-04-05               5              1\n",
       "          2016-04-06               6              1\n",
       "          2016-04-07               7              1\n",
       "          2016-04-08               8              2\n",
       "          2016-04-09               9              2\n",
       "          2016-04-10              10              2\n",
       "          2016-04-11              11              2\n",
       "          2016-04-12              12              2\n",
       "          2016-04-13              13              2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = DateTimeFeatures(manual_selection=[\"week_of_month\", \"day_of_quarter\"])\n",
    "X_hat = transformer.fit_transform(X_train)\n",
    "\n",
    "new_cols = [i for i in X_hat if not i in X_train.columns]\n",
    "display(X_hat[new_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "Using the `\"WindowSummarizer\"`, `\"DateTimeFeatures\"` and the `\"make_reduction\"` function we can now set up a working example of a an end to end global forecasting pipeline based on a sample of the M5 competition data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ds40/pydata_berlin/sktime/sktime/utils/datetime.py:105: FutureWarning: Timestamp.freq is deprecated and will be removed in a future version.\n",
      "  if not hasattr(x, \"freq\") or x.freq is None:\n",
      "/home/ds40/pydata_berlin/sktime/sktime/utils/datetime.py:107: FutureWarning: Timestamp.freq is deprecated and will be removed in a future version.\n",
      "  by *= x.freq\n",
      "/home/ds40/pydata_berlin/sktime/sktime/forecasting/base/_fh.py:565: FutureWarning: Timestamp.freqstr is deprecated and will be removed in a future version.\n",
      "  cutoff = _coerce_to_period(cutoff, freq=cutoff.freqstr)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instances</th>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>756.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2016-03-15</th>\n",
       "      <td>1901.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y\n",
       "instances timepoints         \n",
       "1         2016-03-15   756.67\n",
       "2         2016-03-15  1901.15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fh = ForecastingHorizon(X_test.index, is_relative=False)\n",
    "pipe = ForecastingPipeline(\n",
    "    steps=[\n",
    "        (\"event_dynamics\", WindowSummarizer(n_jobs=-1, **kwargs, target_cols=[\"event_type_1\",\"event_type_2\"])),\n",
    "        (\"snap_dynamics\", WindowSummarizer(n_jobs=-1, target_cols=[\"snap\"])),\n",
    "        (\"daily_season\", DateTimeFeatures(ts_freq=\"D\")),\n",
    "        (\"forecaster\", forecaster),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#display(X_train)\n",
    "pipe_return = pipe.fit(y_train, X_train)\n",
    "y_pred1 = pipe_return.predict(fh=1, X=X_test)\n",
    "display(y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road ahead\n",
    "\n",
    "The major steps needed for global forecasting have been implemented, but a key challenge remains. \n",
    "\n",
    "<img src=\"./img/road_ahead.PNG\" width=\"1000\" alt=\"road ahead\">\n",
    "\n",
    "Due to the complexity of time series feature generation, **cross validation** for tree based models is still a very manual issue requiring expertise and often just trial and error approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intend to integrate the following global forecasting features into the next SKTIME releases:\n",
    "* Automated tuning strategy:\n",
    "    * complexity argument taking into account the frequency / length of time series and internal heuristic to generate appropriate features\n",
    "    * autodetect approraite features based on autocorrelation function and seasonsality detection\n",
    "    * Using feature importances to identify relevant features\n",
    "\n",
    "\n",
    "* Strategies for extrapolation \n",
    "    * Trend removal and addition\n",
    "    * Postprocessing based on other models that recognize trends\n",
    "    * Multivariate trend removal to detect / remove common trends\n",
    "\n",
    "* Quantile Regression \n",
    "    * Tree based models were not only winning solution in M5 for point forecasts, but also quantile regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions welcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blab lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hierarchical reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forecast reconciliation = ensuring that linear hierarchy dependencies are met,\\\n",
    "e.g., \"sum of individual shop sales in Berlin must equal sum of total sales in Berlin\"\\\n",
    "requires hierarchical (or panel) data, usually involves totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sktime provides functionality for reconciliation:\n",
    "\n",
    "* data container convention for node-wise aggregates\n",
    "* functionality to compute node-wise aggregates - `Aggregator`\n",
    "* transformer implementing reconiliation logic - `Reconciler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The node-wise aggregate data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` uses a special case of the `pd_multiindex_hier` format to store node-wise aggregates:\n",
    "\n",
    "* a `__total` index element in an instance (non-time-like) level indicates summation over all instances below that level\n",
    "* the `__total` index element is reserved and cannot be used for anything else\n",
    "* entries below a `__total` index element are sums of entries over all other instances in the same levels where a `__total` element is found\n",
    "\n",
    "example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_hier_total_example\n",
    "\n",
    "load_hier_total_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The aggregation transformer\n",
    "\n",
    "The node-wise aggregated format can be obtained by applying the `Aggregator` transformer.\n",
    "\n",
    "In a pipeline with non-aggregate dinput, this allows making forecasts by totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import get_examples\n",
    "\n",
    "y_hier = get_examples(\"pd_multiindex_hier\")[1]\n",
    "y_hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.hierarchical.aggregate import Aggregator\n",
    "\n",
    "Aggregator().fit_transform(y_hier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If used at the start of a pipeline, forecasts are made for node `__total`-s as well as individual instances.\n",
    "\n",
    "Note: in general, this does not result in a reconciled forecast, i.e., forecast totals will not add up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "pipeline_to_forecast_totals = Aggregator() * NaiveForecaster()\n",
    "\n",
    "pipeline_to_forecast_totals.fit(y_hier, fh=[1, 2])\n",
    "pipeline_to_forecast_totals.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If used at the end of a pipeline, forecasts are reconciled bottom-up.\n",
    "\n",
    "That will result in a reconciled forecast, although bottom-up may not be the method of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "\n",
    "pipeline_to_forecast_totals = NaiveForecaster() * Aggregator()\n",
    "\n",
    "pipeline_to_forecast_totals.fit(y_hier, fh=[1, 2])\n",
    "pipeline_to_forecast_totals.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fur transformer-like reconciliation, use the `Reconciler`.\n",
    "It supports advanced techniques such as OLS and WLS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.hierarchical.reconcile import Reconciler\n",
    "\n",
    "pipeline_with_reconciliation = Aggregator() * NaiveForecaster() * Reconciler(method=\"ols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_to_forecast_totals.fit(y_hier, fh=[1, 2])\n",
    "pipeline_to_forecast_totals.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roadmap items:\n",
    "\n",
    "* reconciliation of wrapper type\n",
    "* reconciliation & global forecasting\n",
    "* probabilistic reconciliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Credits\n",
    "\n",
    "notebook creation: danbartl, fkiraly\n",
    "\n",
    "hierarchical forecasting framework: ciaran-g, fkiraly\\\n",
    "reduction compatibility with hierarchical forecasting: danbartl\\\n",
    "window summarizer, reduction with transform-from-y: danbartl\\\n",
    "aggregation and reconciliation: ciaran-g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
